{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24846c3b-382e-472b-bc1d-e2ee39985d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.nn import GCNConv\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import spacy\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from datasets import load_dataset\n",
    "\n",
    "seed = 42\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51c675c2-6bab-4ebe-9de1-c9ce606b8540",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset esnli (/home/ec2-user/.cache/huggingface/datasets/esnli/plain_text/0.0.2/a160e6a02bbb8d828c738918dafec4e7d298782c334b5109af632fec6d779bbc)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14b6e7a8be2a4f2ba7a1c061bfec3915",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(54937, 9842)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the e-SNLI dataset\n",
    "dataset = load_dataset(\"esnli\")\n",
    "\n",
    "train_dataset = dataset['train']\n",
    "eval_dataset = dataset['validation']\n",
    "#test_dataset = dataset['test']\n",
    "\n",
    "indices = list(range(0, len(train_dataset), 10))  # Select every 10th index\n",
    "train_dataset = train_dataset.select(indices)\n",
    "\n",
    "len(train_dataset), len(eval_dataset)#, len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ebae4e0-ee80-4454-b42f-a94863efa626",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dct = {0: \"entailment\", 1: \"neutral\", 2: \"contradiction\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33a2a7c4-c217-4fb7-88b7-2afff4049c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = \"../expt1/flan_t5_esnli/checkpoint-\" + str(18887)\n",
    "tokenizer = T5Tokenizer.from_pretrained(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df454f4e-96f0-466e-9421-e976682960c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SpaCy for dependency parsing\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Generate Graph Features Using SpaCy\n",
    "def get_dependency_graph(text):\n",
    "    # Parse the text with SpaCy\n",
    "    doc = nlp(text)\n",
    "    nodes = [tokenizer(token.text, truncation=True, padding=\"max_length\", max_length=512, return_tensors=\"pt\")[\"input_ids\"][0] for token in doc]\n",
    "    edges = [[(token.head.i) for token in doc if token.dep_ != 'punct'],\n",
    "             [(token.i) for token in doc if token.dep_ != 'punct']]\n",
    "    return nodes, edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0df9b1e7-597b-4c2f-bf92-d3ee909f5958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9b57eab9d4f4352a3c56f0392a191bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/54937 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0360eb42a605486cbd51956d4ef4251c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9842 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Preprocessing function\n",
    "def preprocess(example):\n",
    "    # Prepare input and output text\n",
    "    input_text = f\"Premise: {example['premise']} Hypothesis: {example['hypothesis']} What is the relationship? Explain your answer.\"\n",
    "    output_text = f\"{label_dct[example['label']]}: {example['explanation_1']}. {example['explanation_2']}. {example['explanation_3']}.\"\n",
    "\n",
    "    # Tokenize input and output\n",
    "    input_encoding = tokenizer(input_text, truncation=True, padding=\"max_length\", max_length=512, return_tensors=\"pt\")\n",
    "    output_encoding = tokenizer(output_text, truncation=True, padding=\"max_length\", max_length=512, return_tensors=\"pt\")\n",
    "    \n",
    "    # Generate graphs for both premise and hypothesis\n",
    "    combined_nodes, combined_edges = get_dependency_graph(f\"Premise: {example['premise']} Hypothesis: {example['hypothesis']}\")\n",
    "    combined_nodes = torch.stack(combined_nodes)\n",
    "    combined_nodes = nn.functional.pad(combined_nodes, (0, 0, 0, 120-combined_nodes.shape[0]))\n",
    "    combined_edges = torch.tensor(combined_edges)\n",
    "    combined_edges = nn.functional.pad(combined_edges, (0, 120-combined_edges.shape[1]), value=-1)\n",
    "\n",
    "    # Create a dictionary to return\n",
    "    return {\n",
    "        \"input_ids\": input_encoding[\"input_ids\"][0],  # Remove batch dimension\n",
    "        \"attention_mask\": input_encoding[\"attention_mask\"][0],  # Remove batch dimension\n",
    "        \"labels\": output_encoding[\"input_ids\"][0], # Remove batch dimension\n",
    "        \"combined_nodes\": combined_nodes,\n",
    "        \"combined_edges\": combined_edges,\n",
    "    }\n",
    "\n",
    "# Apply preprocessing\n",
    "train_dataset = train_dataset.map(\n",
    "    preprocess,\n",
    "    remove_columns=['premise', 'hypothesis', 'label', 'explanation_1', 'explanation_2', 'explanation_3'],\n",
    "    load_from_cache_file=False\n",
    ")\n",
    "eval_dataset = eval_dataset.map(\n",
    "    preprocess,\n",
    "    remove_columns=['premise', 'hypothesis', 'label', 'explanation_1', 'explanation_2', 'explanation_3'],\n",
    "    load_from_cache_file=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09d7b3ed-b9d4-4041-8808-b0806000a39b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n"
     ]
    }
   ],
   "source": [
    "train_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\", \"combined_nodes\", \"combined_edges\"])\n",
    "eval_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\", \"combined_nodes\", \"combined_edges\"])\n",
    "print(train_dataset[0]['input_ids'].shape)  # Should show (512,)\n",
    "print(train_dataset[0]['attention_mask'].shape)  # Should show (512,)\n",
    "print(train_dataset[0]['labels'].shape)  # Should show (512,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a09dd39-4e56-4a5e-a087-0874f503e4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the GCN model that processes graph data and outputs embeddings\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, 64)\n",
    "        self.conv2 = GCNConv(64, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6823e5a6-cb1e-4046-8412-c7e6965184df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class T5WithUnifiedGCN(nn.Module):\n",
    "    def __init__(self, t5_model, gcn_model):\n",
    "        super(T5WithUnifiedGCN, self).__init__()\n",
    "        self.t5 = t5_model\n",
    "        self.gcn = gcn_model\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, combined_nodes, combined_edges, labels):\n",
    "        # Step 1: Get embeddings from the T5 encoder (for the combined input)\n",
    "        encoder_outputs = self.t5.encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        t5_embeddings = encoder_outputs.last_hidden_state  # Shape: (batch_size, sequence_length, embedding_dim)\n",
    "\n",
    "        # Step 2: Generate a graph embedding from the GCN using the combined sequence\n",
    "        #combined_edges = torch.stack(combined_edges)\n",
    "        combined_edges = combined_edges[combined_edges!=-1].reshape((2,-1))\n",
    "        #combined_nodes = torch.stack(combined_nodes)\n",
    "        zero_rows = (combined_nodes==0).all(dim=1)\n",
    "        combined_nodes = combined_nodes[~zero_rows]\n",
    "        graph_embeddings = self.gcn(combined_nodes.to(torch.float), combined_edges.to(torch.long)).unsqueeze(0)\n",
    "        \n",
    "        # Step 4: Concatenate the T5 embeddings with the graph embeddings\n",
    "        combined_embeddings = torch.cat([t5_embeddings, graph_embeddings], dim=1)\n",
    "        \n",
    "        # Step 5: Pass the combined embeddings to the T5 decoder (for sequence generation or classification)\n",
    "        decoder_outputs = self.t5.decoder(input_ids=input_ids, encoder_hidden_states=combined_embeddings, attention_mask=attention_mask)\n",
    "        sequence_output = decoder_outputs[0]\n",
    "\n",
    "        if self.t5.config.tie_word_embeddings:\n",
    "            # Rescale output before projecting on vocab\n",
    "            # See https://github.com/tensorflow/mesh/blob/fa19d69eafc9a482aff0b59ddd96b025c0cb207d/mesh_tensorflow/transformer/transformer.py#L586\n",
    "            sequence_output = sequence_output * (self.model_dim**-0.5)\n",
    "\n",
    "        lm_logits = self.t5.lm_head(sequence_output)\n",
    "\n",
    "        \"\"\"\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = CrossEntropyLoss(ignore_index=-100)\n",
    "            # move labels to correct device to enable PP\n",
    "            labels = labels.to(lm_logits.device)\n",
    "            loss = loss_fct(lm_logits.view(-1, lm_logits.size(-1)), labels.view(-1))\n",
    "        \"\"\"\n",
    "\n",
    "        output = (lm_logits,) + decoder_outputs[1:] + encoder_outputs[0:]\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cff31322-4dbc-4c2b-8aa5-a821c3f48a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_output_sequences(model, input_ids, attention_mask, combined_nodes, combined_edges, tokenizer, max_length=50, num_beams=5):\n",
    "    \"\"\"\n",
    "    Generates sequences from the T5WithUnifiedGCN model, which includes the T5 model and Graph Convolution Network.\n",
    "\n",
    "    Args:\n",
    "        model: T5WithUnifiedGCN model\n",
    "        input_ids: Tensor of input token IDs (batch_size, seq_length)\n",
    "        attention_mask: Attention mask for the input (batch_size, seq_length)\n",
    "        combined_nodes: The combined graph nodes (batch_size, num_nodes)\n",
    "        combined_edges: The combined graph edges (batch_size, num_edges)\n",
    "        tokenizer: The T5 tokenizer\n",
    "        max_length: The maximum length of the generated sequences\n",
    "        num_beams: Number of beams for beam search (for controlled generation)\n",
    "\n",
    "    Returns:\n",
    "        Generated sequences (List of strings)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ensure the model is in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Pass inputs through the model\n",
    "    with torch.no_grad():\n",
    "        # Get the logits and other outputs from the forward pass\n",
    "        outputs = model(input_ids=input_ids, \n",
    "                        attention_mask=attention_mask, \n",
    "                        combined_nodes=combined_nodes, \n",
    "                        combined_edges=combined_edges, \n",
    "                        labels=None)  # We do not need labels during inference\n",
    "        \n",
    "        lm_logits = outputs[0]  # (batch_size, seq_len, vocab_size)\n",
    "\n",
    "    # Decode the output sequences\n",
    "    # Get the token probabilities and use the argmax or sample from the distribution\n",
    "    # You can use beam search or greedy decoding for generating sequences\n",
    "\n",
    "    generated_sequences = []\n",
    "    for batch_idx in range(lm_logits.size(0)):  # Iterate over each batch\n",
    "        # Use beam search or greedy decoding (beam search is usually more sophisticated)\n",
    "        # Using beam search here for better results\n",
    "        generated_ids = model.t5.generate(\n",
    "            input_ids=input_ids[batch_idx:batch_idx+1],  # Process each sample individually\n",
    "            attention_mask=attention_mask[batch_idx:batch_idx+1],\n",
    "            max_length=max_length,\n",
    "            num_beams=num_beams,\n",
    "            early_stopping=True\n",
    "        )\n",
    "        \n",
    "        # Decode the generated token IDs to strings\n",
    "        decoded_sequence = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "        generated_sequences.append(decoded_sequence)\n",
    "\n",
    "    return generated_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee6ddb72-f06d-4d1e-ad21-0686bf589a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "t5_model = T5ForConditionalGeneration.from_pretrained(checkpoint_path)\n",
    "gcn_model = GCN(in_channels=512, out_channels=512)\n",
    "\n",
    "# Create your model\n",
    "model = T5WithUnifiedGCN(t5_model, gcn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47c7ed5-1040-4068-a890-322fc026d00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#outed = model(train_dataset[0][\"input_ids\"].unsqueeze(0), train_dataset[0][\"attention_mask\"].unsqueeze(0),\n",
    "#              train_dataset[0][\"combined_nodes\"], train_dataset[0][\"combined_edges\"], train_dataset[0][\"labels\"].unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5162c01b-ed1b-475b-81b9-1a6902b48c2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_output_sequences(model, train_dataset[1][\"input_ids\"].unsqueeze(0), train_dataset[1][\"attention_mask\"].unsqueeze(0),\n",
    "              torch.stack(train_dataset[1][\"combined_nodes\"]), torch.stack(train_dataset[1][\"combined_edges\"]), tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "572e85a0-2bbc-43b2-aa5a-78de282ab3f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/1:  66%|████████████████████████████████████████████████████████████████████████████████████████████▏                                              | 36452/54937 [13:12:29<6:41:52,  1.30s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 64\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m \u001b[43mtrain_without_dataloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fct\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[15], line 53\u001b[0m, in \u001b[0;36mtrain_without_dataloader\u001b[0;34m(model, dataset, optimizer, loss_fct, num_epochs)\u001b[0m\n\u001b[1;32m     50\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fct(lm_logits\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, lm_logits\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)), labels\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Backpropagation and optimizer step\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# Accumulate the loss for reporting\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "learning_rate = 0.001\n",
    "optimizer = AdamW(\n",
    "    model.parameters(),\n",
    "    lr=learning_rate,\n",
    "    betas=(0.9, 0.999),\n",
    "    eps=1e-08,\n",
    ")\n",
    "loss_fct = CrossEntropyLoss(ignore_index=-100)  # For sequence generation\n",
    "\n",
    "# Move the model to the correct device\n",
    "device = 'cpu'\n",
    "model.to(device)\n",
    "\n",
    "# Train the model manually without DataLoader\n",
    "def train_without_dataloader(model, dataset, optimizer, loss_fct, num_epochs=3):\n",
    "    model.train()  # Set the model to training mode\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for idx in tqdm(range(len(dataset)), desc=f\"Training Epoch {epoch + 1}/{num_epochs}\"):\n",
    "            # Get the data point from the dataset\n",
    "            batch = dataset[idx]  # Get item at index idx\n",
    "\n",
    "            # Move tensors to the correct device\n",
    "            input_ids = batch['input_ids'].to(device).unsqueeze(0)\n",
    "            attention_mask = batch['attention_mask'].to(device).unsqueeze(0)\n",
    "            labels = batch['labels'].to(device).unsqueeze(0)\n",
    "            combined_nodes = torch.stack(batch['combined_nodes']).to(device)\n",
    "            combined_edges = torch.stack(batch['combined_edges']).to(device)\n",
    "\n",
    "            # Zero the gradients before each pass\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass through the model\n",
    "            outputs = model(input_ids=input_ids, \n",
    "                            attention_mask=attention_mask, \n",
    "                            combined_nodes=combined_nodes, \n",
    "                            combined_edges=combined_edges, \n",
    "                            labels=labels)\n",
    "\n",
    "            # Get the logits\n",
    "            lm_logits = outputs[0]\n",
    "            \n",
    "            # Calculate the loss\n",
    "            loss = loss_fct(lm_logits.view(-1, lm_logits.size(-1)), labels.view(-1))\n",
    "\n",
    "            # Backpropagation and optimizer step\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Accumulate the loss for reporting\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        # Print the average loss for the epoch\n",
    "        avg_loss = total_loss / len(dataset)\n",
    "        print(f\"Epoch {epoch + 1}, Loss: {avg_loss}\")\n",
    "\n",
    "# Train the model\n",
    "train_without_dataloader(model, train_dataset, optimizer, loss_fct, num_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4e64f692-5e4f-44c6-a389-6ec3a66cfb61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5WithUnifiedGCN(\n",
       "  (t5): T5ForConditionalGeneration(\n",
       "    (shared): Embedding(32128, 512)\n",
       "    (encoder): T5Stack(\n",
       "      (embed_tokens): Embedding(32128, 512)\n",
       "      (block): ModuleList(\n",
       "        (0): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "                (relative_attention_bias): Embedding(32, 6)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedActDense(\n",
       "                (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "                (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "                (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1-7): 7 x T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedActDense(\n",
       "                (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "                (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "                (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (final_layer_norm): T5LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (decoder): T5Stack(\n",
       "      (embed_tokens): Embedding(32128, 512)\n",
       "      (block): ModuleList(\n",
       "        (0): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "                (relative_attention_bias): Embedding(32, 6)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedActDense(\n",
       "                (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "                (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "                (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1-7): 7 x T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedActDense(\n",
       "                (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "                (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "                (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (final_layer_norm): T5LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
       "  )\n",
       "  (gcn): GCN(\n",
       "    (conv1): GCNConv(512, 64)\n",
       "    (conv2): GCNConv(64, 512)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74a3165-fda5-411c-9da0-65a810b86e16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
